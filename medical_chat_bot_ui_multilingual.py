import streamlit as st
import requests
import json
import os

# --- Configuration ---
# Your API key will be provided by the Canvas environment if left as an empty string.
# IMPORTANT: For Streamlit Cloud, remember to set this as a secret in your app settings.
# For local testing, ensure GEMINI_API_KEY is set in .streamlit/secrets.toml or as an environment variable.
if "GEMINI_API_KEY" in st.secrets:
    API_KEY = st.secrets["GEMINI_API_KEY"]
elif os.getenv("GEMINI_API_KEY"):
    API_KEY = os.getenv("GEMINI_API_KEY")
else:
    API_KEY = "" # Fallback for local dev if not set via env var or secrets; will cause 403 error without a key.
    st.error("API Key not found. Please set GEMINI_API_KEY in .streamlit/secrets.toml or as an environment variable.")

API_URL = "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key="

# --- Language Definitions ---
LANGUAGE_MAP = {
    "English": {
        "model_instruction": "English",
        "greeting": "Hello! I'm your online Doctor. How can I help you today?",
        "disclaimer": "ЁЯЪи **Disclaimer:** I am an AI and cannot provide medical diagnoses, prescriptions, or professional medical advice. Always consult a qualified healthcare professional for any medical concerns.",
        "placeholder": "Ask your medical question here...",
        "thinking": "Thinking...",
        "api_error_response": "I'm sorry, I couldn't get a clear response from the medical assistant at this moment. Please try again.",
        "http_error": "I'm experiencing a problem connecting to the medical assistant. Please ensure your API key is correct.",
        "connection_error": "I couldn't connect to the internet. Please check your connection.",
        "timeout_error": "The request took too long. Please try again.",
        "unknown_error": "An unexpected error occurred while communicating. Please try again.",
        "json_error": "I received an unreadable response from the medical assistant. Please try again.",
        "api_key_missing": "Error: API Key is missing. Please configure it."
    },
    "Hindi": {
        "model_instruction": "Hindi",       
        "greeting": "рдирдорд╕реНрддреЗ! рдореИрдВ рдЖрдкрдХрд╛ рдореЗрдбрд┐рдХрд▓ рдЕрд╕рд┐рд╕реНрдЯреЗрдВрдЯ рдмреЙрдЯ рд╣реВрдБред рдореИрдВ рдЖрдЬ рдЖрдкрдХреА рдХреИрд╕реЗ рдорджрдж рдХрд░ рд╕рдХрддрд╛ рд╣реВрдБ?",
        "disclaimer": "ЁЯЪи: рдореИрдВ рдПрдХ AI рд╣реВрдБ рдФрд░ рдЪрд┐рдХрд┐рддреНрд╕реАрдп рдирд┐рджрд╛рди, рдиреБрд╕реНрдЦреЗ рдпрд╛ рдкреЗрд╢реЗрд╡рд░ рдЪрд┐рдХрд┐рддреНрд╕реАрдп рд╕рд▓рд╛рд╣ рдкреНрд░рджрд╛рди рдирд╣реАрдВ рдХрд░ рд╕рдХрддрд╛ред рдХрд┐рд╕реА рднреА рдЪрд┐рдХрд┐рддреНрд╕реАрдп рдЪрд┐рдВрддрд╛ рдХреЗ рд▓рд┐рдП рд╣рдореЗрд╢рд╛ рдПрдХ рдпреЛрдЧреНрдп рд╕реНрд╡рд╛рд╕реНрдереНрдп рдкреЗрд╢реЗрд╡рд░ рд╕реЗ рдкрд░рд╛рдорд░реНрд╢ рдХрд░реЗрдВред",
        "placeholder": "рдпрд╣рд╛рдВ рдЕрдкрдирд╛ рдЪрд┐рдХрд┐рддреНрд╕реАрдп рдкреНрд░рд╢реНрди рдкреВрдЫреЗрдВ...",
        "thinking": "рд╕реЛрдЪ рд░рд╣рд╛ рд╣реВрдБ...",
        "api_error_response": "рдХреНрд╖рдорд╛ рдХрд░реЗрдВ, рдореБрдЭреЗ рдЗрд╕ рд╕рдордп рдореЗрдбрд┐рдХрд▓ рдЕрд╕рд┐рд╕реНрдЯреЗрдВрдЯ рд╕реЗ рд╕реНрдкрд╖реНрдЯ рдкреНрд░рддрд┐рдХреНрд░рд┐рдпрд╛ рдирд╣реАрдВ рдорд┐рд▓ рдкрд╛рдИред рдХреГрдкрдпрд╛ рдкреБрдирдГ рдкреНрд░рдпрд╛рд╕ рдХрд░реЗрдВред",
        "http_error": "рдореБрдЭреЗ рдореЗрдбрд┐рдХрд▓ рдЕрд╕рд┐рд╕реНрдЯреЗрдВрдЯ рд╕реЗ рдХрдиреЗрдХреНрдЯ рдХрд░рдиреЗ рдореЗрдВ рд╕рдорд╕реНрдпрд╛ рдЖ рд░рд╣реА рд╣реИред рдХреГрдкрдпрд╛ рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдХрд░реЗрдВ рдХрд┐ рдЖрдкрдХреА API рдХреБрдВрдЬреА рд╕рд╣реА рд╣реИред",
        "connection_error": "рдореИрдВ рдЗрдВрдЯрд░рдиреЗрдЯ рд╕реЗ рдХрдиреЗрдХреНрдЯ рдирд╣реАрдВ рд╣реЛ рд╕рдХрд╛ред рдХреГрдкрдпрд╛ рдЕрдкрдирд╛ рдЗрдВрдЯрд░рдиреЗрдЯ рдХрдиреЗрдХреНрд╢рди рдЬрд╛рдВрдЪреЗрдВред",
        "timeout_error": "рдЕрдиреБрд░реЛрдз рдореЗрдВ рдмрд╣реБрдд рдЕрдзрд┐рдХ рд╕рдордп рд▓рдЧрд╛ред рдХреГрдкрдпрд╛ рдкреБрдирдГ рдкреНрд░рдпрд╛рд╕ рдХрд░реЗрдВред",
        "unknown_error": "рд╕рдВрдЪрд╛рд░ рдХрд░рддреЗ рд╕рдордп рдПрдХ рдЕрдкреНрд░рддреНрдпрд╛рд╢рд┐рдд рддреНрд░реБрдЯрд┐ рд╣реБрдИред рдХреГрдкрдпрд╛ рдкреБрдирдГ рдкреНрд░рдпрд╛рд╕ рдХрд░реЗрдВред",
        "json_error": "рдореБрдЭреЗ рдореЗрдбрд┐рдХрд▓ рдЕрд╕рд┐рд╕реНрдЯреЗрдВрдЯ рд╕реЗ рдПрдХ рдЕрдкрдардиреАрдп рдкреНрд░рддрд┐рдХреНрд░рд┐рдпрд╛ рдорд┐рд▓реАред рдХреГрдкрдпрд╛ рдкреБрдирдГ рдкреНрд░рдпрд╛рд╕ рдХрд░реЗрдВред",
        "api_key_missing": "рддреНрд░реБрдЯрд┐: API рдХреБрдВрдЬреА рдЧреБрдо рд╣реИред рдХреГрдкрдпрд╛ рдЗрд╕реЗ рдХреЙрдиреНрдлрд╝рд┐рдЧрд░ рдХрд░реЗрдВред"
    },
    "Bengali": {
        "model_instruction": "Bengali",
        "greeting": "ржиржорж╕рзНржХрж╛рж░! ржЖржорж┐ ржЖржкржирж╛рж░ ржорзЗржбрж┐ржХрзЗрж▓ ржЕрзНржпрж╛рж╕рж┐рж╕рзНржЯрзНржпрж╛ржирзНржЯ ржмржЯред ржЖржорж┐ ржЖржЬ ржЖржкржирж╛ржХрзЗ ржХрзАржнрж╛ржмрзЗ рж╕рж╛рж╣рж╛ржпрзНржп ржХрж░рждрзЗ ржкрж╛рж░рж┐?",
        "disclaimer": "ЁЯЪи: ржЖржорж┐ ржПржХржЯрж┐ AI ржПржмржВ ржЪрж┐ржХрж┐рзОрж╕рж╛рж░ ржирж┐рж░рзНржгржпрж╝, ржкрзНрж░рзЗрж╕ржХрзНрж░рж┐ржкрж╢ржи, ржмрж╛ ржкрзЗрж╢рж╛ржжрж╛рж░ ржЪрж┐ржХрж┐рзОрж╕рж╛ ржкрж░рж╛ржорж░рзНрж╢ ржкрзНрж░ржжрж╛ржи ржХрж░рждрзЗ ржкрж╛рж░рж┐ ржирж╛ред ржпрзЗржХрзЛржирзЛ ржЪрж┐ржХрж┐рзОрж╕рж╛рж░ ржЬржирзНржп рж╕рж░рзНржмржжрж╛ ржПржХржЬржи ржпрзЛржЧрзНржп рж╕рзНржмрж╛рж╕рзНржерзНржпрж╕рзЗржмрж╛ ржкрзЗрж╢рж╛ржжрж╛рж░рзЗрж░ рж╕рж╛ржерзЗ ржкрж░рж╛ржорж░рзНрж╢ ржХрж░рзБржиред",
        "placeholder": "ржПржЦрж╛ржирзЗ ржЖржкржирж╛рж░ ржЪрж┐ржХрж┐рзОрж╕рж╛ ржкрзНрж░рж╢рзНржи ржЬрж┐ржЬрзНржЮрж╛рж╕рж╛ ржХрж░рзБржи...",
        "thinking": "ржнрж╛ржмржЫрж┐...",
        "api_error_response": "ржжрзБржГржЦрж┐ржд, ржПржЗ ржорзБрж╣рзВрж░рзНрждрзЗ ржЖржорж┐ ржорзЗржбрж┐ржХрзЗрж▓ ржЕрзНржпрж╛рж╕рж┐рж╕рзНржЯрзНржпрж╛ржирзНржЯрзЗрж░ ржХрж╛ржЫ ржерзЗржХрзЗ рж╕рзНржкрж╖рзНржЯ ржкрзНрж░рждрж┐ржХрзНрж░рж┐ржпрж╝рж╛ ржкрзЗрждрзЗ ржкрж╛рж░рж┐ржирж┐ред ржЕржирзБржЧрзНрж░рж╣ ржХрж░рзЗ ржЖржмрж╛рж░ ржЪрзЗрж╖рзНржЯрж╛ ржХрж░рзБржиред",
        "http_error": "ржорзЗржбрж┐ржХрзЗрж▓ ржЕрзНржпрж╛рж╕рж┐рж╕рзНржЯрзНржпрж╛ржирзНржЯрзЗрж░ рж╕рж╛ржерзЗ рж╕ржВржпрзЛржЧ ржХрж░рждрзЗ рж╕ржорж╕рзНржпрж╛ рж╣ржЪрзНржЫрзЗред ржЕржирзБржЧрзНрж░рж╣ ржХрж░рзЗ ржирж┐рж╢рзНржЪрж┐ржд ржХрж░рзБржи ржЖржкржирж╛рж░ API ржХрзА рж╕ржарж┐ржХред",
        "connection_error": "ржЖржорж┐ ржЗржирзНржЯрж╛рж░ржирзЗржЯрзЗрж░ рж╕рж╛ржерзЗ рж╕ржВржпрзЛржЧ ржХрж░рждрзЗ ржкрж╛рж░рж┐ржирж┐ред ржЕржирзБржЧрзНрж░рж╣ ржХрж░рзЗ ржЖржкржирж╛рж░ ржЗржирзНржЯрж╛рж░ржирзЗржЯ рж╕ржВржпрзЛржЧ ржкрж░рзАржХрзНрж╖рж╛ ржХрж░рзБржиред",
        "timeout_error": "ржЕржирзБрж░рзЛржзржЯрж┐ рж╕ржорзНржкрзВрж░рзНржг рж╣рждрзЗ ржЕржирзЗржХ ржмрзЗрж╢рж┐ рж╕ржоржпрж╝ рж▓рзЗржЧрзЗржЫрзЗред ржЕржирзБржЧрзНрж░рж╣ ржХрж░рзЗ ржЖржмрж╛рж░ ржЪрзЗрж╖рзНржЯрж╛ ржХрж░рзБржиред",
        "unknown_error": "ржпрзЛржЧрж╛ржпрзЛржЧ ржХрж░рж╛рж░ рж╕ржоржпрж╝ ржПржХржЯрж┐ ржЕржкрзНрж░рждрзНржпрж╛рж╢рж┐ржд рждрзНрж░рзБржЯрж┐ ржШржЯрзЗржЫрзЗред ржЕржирзБржЧрзНрж░рж╣ ржХрж░рзЗ ржЖржмрж╛рж░ ржЪрзЗрж╖рзНржЯрж╛ ржХрж░рзБржиред",
        "json_error": "ржорзЗржбрж┐ржХрзЗрж▓ ржЕрзНржпрж╛рж╕рж┐рж╕рзНржЯрзНржпрж╛ржирзНржЯрзЗрж░ ржХрж╛ржЫ ржерзЗржХрзЗ ржПржХржЯрж┐ ржЕржкрж╛ржарзНржп ржкрзНрж░рждрж┐ржХрзНрж░рж┐ржпрж╝рж╛ ржкрзЗржпрж╝рзЗржЫрж┐ред ржЕржирзБржЧрзНрж░рж╣ ржХрж░рзЗ ржЖржмрж╛рж░ ржЪрзЗрж╖рзНржЯрж╛ ржХрж░рзБржиред",
        "api_key_missing": "рждрзНрж░рзБржЯрж┐: API ржХрзА ржЕржирзБржкрж╕рзНржерж┐рждред ржЕржирзБржЧрзНрж░рж╣ ржХрж░рзЗ ржПржЯрж┐ ржХржиржлрж┐ржЧрж╛рж░ ржХрж░рзБржиред"
    }
}

# --- System Prompt Generation ---
def get_system_prompt(language_code):
    """Generates the dynamic system prompt based on the selected language."""
    # The core prompt structure remains the same, but we instruct the model
    # to respond in the chosen language.
    return f"""
    You are a highly intelligent and compassionate Medical Assistant Bot. Your primary goal is to provide accurate, helpful, and context-specific medical guidance while always prioritizing user safety and advising professional consultation.
    The user will interact with you in {language_code}, and you **MUST** respond entirely in {language_code}. Also, you should try to understand the user's prompt even if it's in {language_code}.

    You operate in two modes:

    1.  **General Medical Assistant**:
        * **Purpose**: To address common health concerns, provide general well-being advice, offer preliminary information about mild symptoms, and answer simple health-related inquiries.
        * **Tone**: Friendly, informative, and reassuring.
        * **Examples**: "What are good ways to stay hydrated?", "I have a common cold, what can I do?", "What's the recommended daily intake of Vitamin C?"

    2.  **Specialist Medical Advisor**:
        * **Purpose**: To handle advanced, complex, or highly specific medical queries requiring in-depth knowledge in a particular medical field (e.g., cardiology, neurology, oncology, pharmacology). This mode is triggered by detailed symptom descriptions, questions about specific diseases, drug interactions, or when the user explicitly asks for specialist advice.
        * **Tone**: Professional, precise, and highly detailed.
        * **Examples**: "I have persistent chest pain radiating to my left arm and shortness of breath, what could be the possible causes?", "Tell me about the latest non-surgical treatments for spinal stenosis.", "What are the contraindications for patients with kidney disease taking Metformin?", "Can you explain the mechanism of action of SSRIs?"

    **Instructions for Dynamic Role Switching:**

    * **Default Mode**: Begin every conversation implicitly as a **General Medical Assistant**.
    * **Switching to Specialist**: Analyze the user's query for keywords, detail, and complexity. If the query is detailed, highly specific, involves complex medical terminology, discusses severe symptoms, asks about specific diseases, drug interactions, or requests in-depth medical analysis, **switch to Specialist Medical Advisor mode for that response.**
    * **Acknowledging Specialist Mode**: When you switch to and respond as a **Specialist Medical Advisor**, explicitly state it at the beginning of your response. For example: "As a Specialist Medical Advisor, based on your description,..." or "In my capacity as a Specialist Medical Advisor, I can explain that..."
    * **Always Disclaim**: Regardless of the mode, **ALWAYS** include a disclaimer at the end of every response reminding the user that you are an AI and cannot provide professional medical diagnosis or treatment. **Strongly advise them to consult a qualified healthcare professional for any medical concerns.**
    * **Maintain Context**: Use the chat history to understand the ongoing conversation and provide relevant follow-up.
    * **Clarity and Brevity**: Provide clear, concise, and easy-to-understand information. Avoid medical jargon where simpler terms suffice, but use precise terminology when acting as a specialist.
    * **Ethical Boundaries**: Never give a definitive diagnosis, prescribe medication, or tell the user to stop taking medication. Never encourage self-treatment for serious conditions.
    """

# --- Chatbot Logic (adapted for Streamlit) ---

def call_gemini_api(messages_history, current_language_settings):
    """
    Calls the Gemini API with the given chat history.

    Args:
        messages_history (list): A list of messages for the Gemini API.
        current_language_settings (dict): Language-specific settings for error messages.

    Returns:
        str: The generated response from the Gemini model, or an error message.
    """
    if not API_KEY:
        return current_language_settings["api_key_missing"]

    payload = {
        "contents": messages_history
    }

    try:
        response = requests.post(
            f"{API_URL}{API_KEY}",
            headers={"Content-Type": "application/json"},
            data=json.dumps(payload)
        )
        response.raise_for_status()  # Raise an HTTPError for bad responses (4xx or 5xx)
        result = response.json()

        if result.get("candidates") and result["candidates"][0].get("content") and \
           result["candidates"][0]["content"].get("parts") and \
           result["candidates"][0]["content"]["parts"][0].get("text"):
            return result["candidates"][0]["content"]["parts"][0]["text"]
        else:
            st.error(f"Warning: Unexpected API response structure. Full response: {json.dumps(result, indent=2)}")
            return current_language_settings["api_error_response"]

    except requests.exceptions.HTTPError as e:
        st.error(f"An HTTP error occurred: {e}. Response: {e.response.text}")
        return current_language_settings["http_error"]
    except requests.exceptions.ConnectionError as e:
        st.error(f"A connection error occurred: {e}")
        return current_language_settings["connection_error"]
    except requests.exceptions.Timeout as e:
        st.error(f"The request timed out: {e}")
        return current_language_settings["timeout_error"]
    except requests.exceptions.RequestException as e:
        st.error(f"An unknown request error occurred: {e}")
        return current_language_settings["unknown_error"]
    except json.JSONDecodeError as e:
        st.error(f"Failed to parse the response (JSON error): {e}. Raw response: {response.text if 'response' in locals() else 'No response'}")
        return current_language_settings["json_error"]


# --- Streamlit UI ---

# st.set_page_config(page_header="Online Doctor", page_icon="ЁЯй║", layout="centered")

# Initialize selected_language in session state
if "selected_language" not in st.session_state:
    st.session_state.selected_language = None

# Show language selection if not already selected
if st.session_state.selected_language is None:
    st.subheader("Welcome to your online Doctor:B.Chakraborty")
    st.write("Please select your preferred language:")

    # Using radio buttons for language selection
    selected_lang_display = st.radio(
        "Choose Language",
        list(LANGUAGE_MAP.keys()),
        index=0, # Default to English
        horizontal=True
    )

    if st.button("Start Chat"):
        st.session_state.selected_language = selected_lang_display
        # Initialize chat history with language-specific content
        st.session_state.messages = []
        # Add the system prompt first
        st.session_state.messages.append({"role": "user", "parts": [{"text": get_system_prompt(LANGUAGE_MAP[st.session_state.selected_language]["model_instruction"])}]})
        # Add the initial greeting from the model
        st.session_state.messages.append({"role": "model", "parts": [{"text": LANGUAGE_MAP[st.session_state.selected_language]["greeting"] + "\n\n" + LANGUAGE_MAP[st.session_state.selected_language]["disclaimer"]}]})
        st.rerun() # Rerun the app to show the chat interface
else:
    # Language is selected, display the chat interface
    current_lang_settings = LANGUAGE_MAP[st.session_state.selected_language]

    col1, col2 = st.columns([0.8, 0.2])
    with col1:
        st.subheader(f"ЁЯй║ Online Doctor Biswadeep ({st.session_state.selected_language})")
    with col2:
        if st.button("Change Language", key="change_lang_button"):
            st.session_state.selected_language = None
            st.session_state.messages = [] # Clear messages on language change
            st.rerun()

    st.write(current_lang_settings["disclaimer"])

    # Display chat messages from history on app rerun
    # We skip the very first message (the system prompt) when displaying to the user
    for message in st.session_state.messages[1:]: # Start from index 1 to skip the initial system prompt
        role_for_display = "assistant" if message["role"] == "model" else message["role"]
        with st.chat_message(role_for_display):
            st.markdown(message["parts"][0]["text"])

    # Accept user input
    if prompt := st.chat_input(current_lang_settings["placeholder"]):
        # Add user message to chat history
        st.session_state.messages.append({"role": "user", "parts": [{"text": prompt}]})
        # Display user message in chat message container
        with st.chat_message("user"):
            st.markdown(prompt)

        # Get bot response
        with st.chat_message("assistant"):
            with st.spinner(current_lang_settings["thinking"]):
                # Pass the full conversation history to the API call
                full_conversation_for_api = [
                    {"role": msg["role"], "parts": msg["parts"]}
                    for msg in st.session_state.messages
                ]
                bot_response = call_gemini_api(full_conversation_for_api, current_lang_settings)
                st.markdown(bot_response)

        # Add bot response to chat history
        st.session_state.messages.append({"role": "model", "parts": [{"text": bot_response}]})

